{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 23:37:44.143577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "import clrs\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2 ** 32))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If you don't want BipartiteMatching, just pass empty generator list and\n",
    "# length separately\n",
    "\n",
    "train_sampler_spec = {\n",
    "    'num_samples': 100,\n",
    "    'batch_size':  32,\n",
    "    'schematics':  [\n",
    "        {\n",
    "        'length': 16,\n",
    "        'proportion': 1,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_sampler_spec = {\n",
    "    'num_samples': 40,\n",
    "    'batch_size':  40,\n",
    "    'schematics':  [\n",
    "        {\n",
    "            'length': 64,\n",
    "            'proportion': 1,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def samplers(sampler_spec, **kwargs):\n",
    "    batch_size = sampler_spec.get('batch_size', 1)\n",
    "    num_samples = sampler_spec['num_samples']\n",
    "    if batch_size > num_samples:\n",
    "        batch_size = num_samples\n",
    "\n",
    "    def _iterate_sampler(sampler, batch_size):\n",
    "        while True:\n",
    "            yield sampler.next(batch_size)\n",
    "\n",
    "    sampler, spec = clrs.build_sampler(\n",
    "        name = 'online_testing',\n",
    "        sampler_spec = sampler_spec,\n",
    "        **kwargs)  # number of nodes\n",
    "\n",
    "    sampler = _iterate_sampler(sampler, batch_size = batch_size)\n",
    "    return sampler, spec\n",
    "\n",
    "\n",
    "train_sampler, spec = samplers(train_sampler_spec)\n",
    "test_sampler, _ = samplers(test_sampler_spec)"
   ],
   "metadata": {
    "id": "OEo_Gj1j3Z6M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ef53c51-9bc2-4a49-b4cf-592a32dfa5b7"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 1., ..., 1., 1., 1.],\n       [1., 0., 0., ..., 1., 0., 1.],\n       ...,\n       [1., 1., 1., ..., 1., 1., 1.],\n       [0., 0., 1., ..., 1., 0., 1.],\n       [0., 1., 0., ..., 0., 0., 1.]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(test_sampler)\n",
    "sample.features.inputs[0].data[0]\n",
    "sample.features.hints[0].data[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def define_model(spec, train_sampler, model = \"mpnn\"):\n",
    "    if model == \"mpnn\":\n",
    "        processor_factory = clrs.get_processor_factory('mpnn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 4)  #use_ln => use layer norm\n",
    "    elif model == \"gat\":\n",
    "        processor_factory = clrs.get_processor_factory('gat', use_ln = True, nb_heads = 4, nb_triplet_fts = 4)\n",
    "\n",
    "    elif model == \"mpnndoublemax\":\n",
    "        processor_factory = clrs.get_processor_factory('mpnndoublemax', use_ln = True,\n",
    "                                                       nb_triplet_fts = 0)  #use_ln => use layer norm\n",
    "\n",
    "    elif model == \"gmpnn\":\n",
    "        processor_factory = clrs.get_processor_factory('gmpnn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 4)  #use_ln => use layer norm\n",
    "    elif model == \"pgn\":\n",
    "        processor_factory = clrs.get_processor_factory('pgn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 32)  #use_ln => use layer norm\n",
    "    elif model == \"triplet_pgn_mask\":\n",
    "        processor_factory = clrs.get_processor_factory('triplet_pgn_mask', use_ln = True,\n",
    "                                                       nb_triplet_fts = 32)  #use_ln => use layer norm\n",
    "\n",
    "    model_params = dict(\n",
    "        processor_factory = processor_factory,  # contains the processor_factory\n",
    "        hidden_dim = 32,  # TODO put back to 32 if no difference\n",
    "        encode_hints = True,\n",
    "        decode_hints = True,\n",
    "        #decode_diffs=False,\n",
    "        #hint_teacher_forcing_noise=1.0,\n",
    "        hint_teacher_forcing = 1.0,\n",
    "        use_lstm = False,\n",
    "        learning_rate = 0.001,\n",
    "        checkpoint_path = '/tmp/checkpt',\n",
    "        freeze_processor = False,  # Good for post step\n",
    "        dropout_prob = 0.5,\n",
    "        # nb_msg_passing_steps=3,\n",
    "    )\n",
    "\n",
    "    dummy_trajectory = next(train_sampler)  # jax needs a trajectory that is plausible looking to init\n",
    "\n",
    "    model = clrs.models.BaselineModel(\n",
    "        spec = spec,\n",
    "        dummy_trajectory = dummy_trajectory,\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    model.init(dummy_trajectory.features, 1234)  # 1234 is a random seed\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_model(spec, train_sampler, \"mpnn\")"
   ],
   "metadata": {
    "id": "L-p0jOCq5sPV"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# No evaluation since we are postprocessing with soft: TO CHANGE -> baselines.py line 336 outs change hard to False\n",
    "# step = 0\n",
    "#\n",
    "# while step <= 1:\n",
    "#     feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "#     rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "#     cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "#     rng_key = new_rng_key\n",
    "#     if step % 10 == 0:\n",
    "#         print(step)\n",
    "#     step += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, epochs, train_sampler, test_sampler):\n",
    "    step = 0\n",
    "    rng_key = jax.random.PRNGKey(rng.randint(2 ** 32))\n",
    "\n",
    "    while step <= epochs:\n",
    "        feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "        # TODO remove - testing if uses hints on tests\n",
    "        # shape = test_feedback.features.hints[0].data[0].shape\n",
    "        # test_feedback.features.hints[0].data = test_feedback.features.hints[0].data[0, :, :].reshape((1, *shape))\n",
    "\n",
    "        rng_key, new_rng_key = jax.random.split(rng_key)  # jax needs new random seed at step\n",
    "        cur_loss = model.feedback(rng_key, feedback)  # loss is contained in model somewhere\n",
    "        rng_key = new_rng_key\n",
    "        if step % 50 == 0:\n",
    "            predictions_val, _ = model.predict(rng_key, feedback.features)\n",
    "            out_val = clrs.evaluate(feedback.outputs, predictions_val)\n",
    "            predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "            out = clrs.evaluate(test_feedback.outputs, predictions)\n",
    "            print(\n",
    "                f'step = {step} | loss = {cur_loss} | val_acc = {out_val[\"score\"]} | test_acc = {out[\"score\"]}')  # here, val accuracy is actually training accuracy, not great but is example\n",
    "        step += 1\n",
    "    return model"
   ],
   "metadata": {
    "id": "3pSKQ2wi62Br",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1acd203-e256-4f39-e059-9c7e55942a87"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | loss = 2.1660819053649902 | val_acc = 0.47500887513160706 | test_acc = 0.513396143913269\n",
      "step = 50 | loss = 0.4169905185699463 | val_acc = 0.006059996783733368 | test_acc = 0.004073990974575281\n",
      "step = 100 | loss = 0.27615106105804443 | val_acc = 0.003404786344617605 | test_acc = 0.002677247626706958\n"
     ]
    }
   ],
   "source": [
    "model = train(model, 100, train_sampler, test_sampler)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_feedback = next(test_sampler)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# test_feedback = next(test_sampler)\n",
    "predictions, _ = model.predict(rng_key, test_feedback.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([ 0.98087317, -0.07416291,  0.98156744,  0.9806936 ,  0.98143446,\n       -0.06535578, -0.07103633,  0.9777561 , -0.06063077,  0.98111415,\n       -0.06765325,  0.9769704 ,  0.98019904, -0.06847873, -0.0817865 ,\n        0.9802213 ,  0.97885627,  0.9815149 , -0.06642177,  0.9826355 ,\n        0.979281  , -0.07321703, -0.07755595, -0.06382804, -0.07131772,\n       -0.06748506, -0.06530993,  0.97771525,  0.9815438 , -0.07130258,\n        0.97742194,  0.9817032 , -0.06612809, -0.07532345,  0.9818983 ,\n       -0.06972069,  0.97804874, -0.07019711,  0.98192054, -0.06860285,\n       -0.07033233,  0.9796916 , -0.06734654, -0.07062507, -0.07609523,\n        0.9808937 , -0.06427146,  0.9773147 ,  0.9782223 , -0.0806498 ,\n       -0.06241468, -0.06299652,  0.9802721 ,  0.98304   , -0.06592128,\n        0.9815593 , -0.07300188,  0.97947204,  0.98258513,  0.979904  ,\n        0.98187655,  0.9812439 ,  0.9805051 ,  0.9758394 ], dtype=float32)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['value'].data[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
