{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import jax\n",
    "import clrs\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2 ** 32))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If you don't want BipartiteMatching, just pass empty generator list and\n",
    "# length separately\n",
    "\n",
    "train_sampler_spec = {\n",
    "    'num_samples': 100,\n",
    "    'batch_size':  32,\n",
    "    'schematics':  [\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 0,\n",
    "            'length':     16,\n",
    "            'kwargs':     {'p': 0.8, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 1,\n",
    "            'length':     3,\n",
    "            'length_2':   15,\n",
    "            'kwargs':     {'p': 0.8, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 0,\n",
    "            'length':     10,\n",
    "            'length_2':   50,\n",
    "            'kwargs':     {'p': 0.1, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_sampler_spec = {\n",
    "    'num_samples': 40,\n",
    "    'batch_size':  40,\n",
    "    'schematics':  [\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 0,\n",
    "            'length':     100,\n",
    "            'kwargs':     {'p': 0.05, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 0,\n",
    "            'length':     16,\n",
    "            'kwargs':     {'p': 0.8, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "        {\n",
    "            'generator':  'ER',\n",
    "            'proportion': 1,\n",
    "            'length':     3,\n",
    "            'length_2':   15,\n",
    "            'kwargs':     {'p': 0.8, 'low': 0, 'high': 1, 'weighted': True},\n",
    "            'online':     True\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def samplers(sampler_spec, **kwargs):\n",
    "    batch_size = sampler_spec.get('batch_size', 1)\n",
    "    num_samples = sampler_spec['num_samples']\n",
    "    if batch_size > num_samples:\n",
    "        batch_size = num_samples\n",
    "\n",
    "    def _iterate_sampler(sampler, batch_size):\n",
    "        while True:\n",
    "            yield sampler.next(batch_size)\n",
    "\n",
    "    sampler, spec = clrs.build_sampler(\n",
    "        name = 'online_bipartite_matching',\n",
    "        sampler_spec = sampler_spec,\n",
    "        **kwargs)  # number of nodes\n",
    "\n",
    "    sampler = _iterate_sampler(sampler, batch_size = batch_size)\n",
    "    return sampler, spec\n",
    "\n",
    "\n",
    "train_sampler, spec = samplers(train_sampler_spec)\n",
    "test_sampler, _ = samplers(test_sampler_spec)"
   ],
   "metadata": {
    "id": "OEo_Gj1j3Z6M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ef53c51-9bc2-4a49-b4cf-592a32dfa5b7"
   },
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n",
      "119\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "(19, 19)"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(test_sampler)\n",
    "sample.features.inputs[1].data[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def define_model(spec, train_sampler, model = \"mpnn\"):\n",
    "    if model == \"mpnn\":\n",
    "        processor_factory = clrs.get_processor_factory('mpnn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 4)  #use_ln => use layer norm\n",
    "    elif model == \"gat\":\n",
    "        processor_factory = clrs.get_processor_factory('gat', use_ln = True, nb_heads = 4, nb_triplet_fts = 4)\n",
    "\n",
    "    elif model == \"mpnndoublemax\":\n",
    "        processor_factory = clrs.get_processor_factory('mpnndoublemax', use_ln = True,\n",
    "                                                       nb_triplet_fts = 0)  #use_ln => use layer norm\n",
    "\n",
    "    elif model == \"gmpnn\":\n",
    "        processor_factory = clrs.get_processor_factory('gmpnn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 4)  #use_ln => use layer norm\n",
    "    elif model == \"pgn\":\n",
    "        processor_factory = clrs.get_processor_factory('pgn', use_ln = True,\n",
    "                                                       nb_triplet_fts = 32)  #use_ln => use layer norm\n",
    "    elif model == \"triplet_pgn_mask\":\n",
    "        processor_factory = clrs.get_processor_factory('triplet_pgn_mask', use_ln = True,\n",
    "                                                       nb_triplet_fts = 32)  #use_ln => use layer norm\n",
    "\n",
    "    model_params = dict(\n",
    "        processor_factory = processor_factory,  # contains the processor_factory\n",
    "        hidden_dim = 32,  # TODO put back to 32 if no difference\n",
    "        encode_hints = True,\n",
    "        decode_hints = True,\n",
    "        #decode_diffs=False,\n",
    "        #hint_teacher_forcing_noise=1.0,\n",
    "        hint_teacher_forcing = 0.5,\n",
    "        use_lstm = False,\n",
    "        learning_rate = 0.001,\n",
    "        checkpoint_path = '/tmp/checkpt',\n",
    "        freeze_processor = False,  # Good for post step\n",
    "        dropout_prob = 0.5,\n",
    "        # nb_msg_passing_steps=3,\n",
    "    )\n",
    "\n",
    "    dummy_trajectory = next(train_sampler)  # jax needs a trajectory that is plausible looking to init\n",
    "\n",
    "    model = clrs.models.BaselineModel(\n",
    "        spec = spec,\n",
    "        dummy_trajectory = dummy_trajectory,\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    model.init(dummy_trajectory.features, 1234)  # 1234 is a random seed\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = define_model(spec, train_sampler, \"mpnn\")"
   ],
   "metadata": {
    "id": "L-p0jOCq5sPV"
   },
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# No evaluation since we are postprocessing with soft: TO CHANGE -> baselines.py line 336 outs change hard to False\n",
    "# step = 0\n",
    "#\n",
    "# while step <= 1:\n",
    "#     feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "#     rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "#     cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "#     rng_key = new_rng_key\n",
    "#     if step % 10 == 0:\n",
    "#         print(step)\n",
    "#     step += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, epochs, train_sampler, test_sampler):\n",
    "    step = 0\n",
    "    rng_key = jax.random.PRNGKey(rng.randint(2 ** 32))\n",
    "\n",
    "    while step <= epochs:\n",
    "        feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "\n",
    "        rng_key, new_rng_key = jax.random.split(rng_key)  # jax needs new random seed at step\n",
    "        cur_loss = model.feedback(rng_key, feedback)  # loss is contained in model somewhere\n",
    "        rng_key = new_rng_key\n",
    "        if step % 10 == 0:\n",
    "            predictions_val, _ = model.predict(rng_key, feedback.features)\n",
    "            out_val = clrs.evaluate(feedback.outputs, predictions_val)\n",
    "            predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "            out = clrs.evaluate(test_feedback.outputs, predictions)\n",
    "            print(\n",
    "                f'step = {step} | loss = {cur_loss} | val_acc = {out_val[\"score\"]} | test_acc = {out[\"score\"]}')  # here, val accuracy is actually training accuracy, not great but is example\n",
    "        # if step % 150 == 0:\n",
    "        # learned, greedy = matching_value(test_feedback, predictions, partial = False, match_rest = False, opt_scipy = True)\n",
    "        # print(f\"**learned: {learned}, greedy: {greedy}**\")\n",
    "        step += 1\n",
    "    return model"
   ],
   "metadata": {
    "id": "3pSKQ2wi62Br",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1acd203-e256-4f39-e059-9c7e55942a87"
   },
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | loss = 2.5965096950531006 | val_acc = 0.8667763471603394 | test_acc = 0.8447368741035461\n",
      "step = 10 | loss = 2.49609375 | val_acc = 0.8996710777282715 | test_acc = 0.8565790057182312\n",
      "step = 20 | loss = 2.5253994464874268 | val_acc = 0.8782894611358643 | test_acc = 0.8302631974220276\n",
      "step = 30 | loss = 2.554109811782837 | val_acc = 0.8585526347160339 | test_acc = 0.8381579518318176\n",
      "step = 40 | loss = 2.468383312225342 | val_acc = 0.9029605388641357 | test_acc = 0.8565790057182312\n",
      "step = 50 | loss = 2.469703435897827 | val_acc = 0.9013158082962036 | test_acc = 0.8684210777282715\n",
      "step = 60 | loss = 2.366101026535034 | val_acc = 0.8815789818763733 | test_acc = 0.8460526466369629\n",
      "step = 70 | loss = 2.2869222164154053 | val_acc = 0.8832237124443054 | test_acc = 0.8697368502616882\n",
      "step = 80 | loss = 2.364321231842041 | val_acc = 0.8634868264198303 | test_acc = 0.8815789818763733\n",
      "step = 90 | loss = 2.220386028289795 | val_acc = 0.8914473652839661 | test_acc = 0.8315789699554443\n",
      "step = 100 | loss = 2.2464914321899414 | val_acc = 0.8684210777282715 | test_acc = 0.8684210777282715\n",
      "step = 110 | loss = 2.399181604385376 | val_acc = 0.8486841917037964 | test_acc = 0.8539474010467529\n",
      "step = 120 | loss = 2.0081710815429688 | val_acc = 0.8717105388641357 | test_acc = 0.8434211015701294\n",
      "step = 130 | loss = 2.111677408218384 | val_acc = 0.8503289818763733 | test_acc = 0.8736842274665833\n",
      "step = 140 | loss = 2.056593656539917 | val_acc = 0.8618420958518982 | test_acc = 0.8355263471603394\n",
      "step = 150 | loss = 2.1973013877868652 | val_acc = 0.8799341917037964 | test_acc = 0.8421052694320679\n",
      "step = 160 | loss = 2.0577850341796875 | val_acc = 0.8980263471603394 | test_acc = 0.8592105507850647\n",
      "step = 170 | loss = 2.017732858657837 | val_acc = 0.8799341917037964 | test_acc = 0.865789532661438\n",
      "step = 180 | loss = 2.021014451980591 | val_acc = 0.8569079041481018 | test_acc = 0.8315789699554443\n",
      "step = 190 | loss = 1.8807185888290405 | val_acc = 0.8700658082962036 | test_acc = 0.8486842513084412\n",
      "step = 200 | loss = 1.7774873971939087 | val_acc = 0.8569079041481018 | test_acc = 0.8263158202171326\n",
      "step = 210 | loss = 2.0907914638519287 | val_acc = 0.8848684430122375 | test_acc = 0.8631579279899597\n",
      "step = 220 | loss = 1.7553831338882446 | val_acc = 0.8585526347160339 | test_acc = 0.8289474248886108\n",
      "step = 230 | loss = 1.9994263648986816 | val_acc = 0.8684210777282715 | test_acc = 0.8526316285133362\n",
      "step = 240 | loss = 1.928887128829956 | val_acc = 0.875 | test_acc = 0.8539474010467529\n",
      "step = 250 | loss = 2.1485633850097656 | val_acc = 0.8848684430122375 | test_acc = 0.8644737005233765\n",
      "step = 260 | loss = 1.8397891521453857 | val_acc = 0.8717105388641357 | test_acc = 0.8500000238418579\n",
      "step = 270 | loss = 1.8916839361190796 | val_acc = 0.8618420958518982 | test_acc = 0.8671053051948547\n",
      "step = 280 | loss = 1.9480600357055664 | val_acc = 0.8799341917037964 | test_acc = 0.8736842274665833\n",
      "step = 290 | loss = 1.6312261819839478 | val_acc = 0.8618420958518982 | test_acc = 0.8447368741035461\n",
      "step = 300 | loss = 1.8488937616348267 | val_acc = 0.8914473652839661 | test_acc = 0.878947377204895\n"
     ]
    }
   ],
   "source": [
    "model = train(model, 300, train_sampler, test_sampler)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def matching_value(samples, predicted_hints, predicted_outputs, predict_outputs = False, predict_match_h = False):\n",
    "    features = samples.features\n",
    "    gt_matchings = samples.outputs[0].data\n",
    "    predicted_matchings = predicted_outputs['match'].data\n",
    "    # inputs for the matrix A are at index 1 (see spec.py)\n",
    "    matrices = features.inputs[1].data\n",
    "    masks = features.inputs[4].data\n",
    "    current_nodes = features.hints[3].data\n",
    "    # If there is no matching of weight > 0, don't count it\n",
    "    count_non_zero_matchings = 0\n",
    "    pred_accuracy = 0\n",
    "    greedy_accuracy = 0\n",
    "\n",
    "    # Iterating over all the samples\n",
    "    for i in range(matrices.shape[0]):\n",
    "        max_weight = compute_matching_weight_from_matching(matrices[i], masks[i], gt_matchings[i], predicted = False)\n",
    "\n",
    "        if max_weight > 0:\n",
    "            if predict_outputs:\n",
    "                preds_weight = compute_matching_weight_from_matching(matrices[i], masks[i], predicted_matchings[i], predicted = True)\n",
    "            elif predict_match_h:\n",
    "                preds_weight = compute_matching_weight_from_match_h(i, matrices[i], masks[i], predicted_hints, current_nodes)\n",
    "            else:\n",
    "                preds_weight = compute_hint_matching_weight(i, matrices[i], masks[i], predicted_hints, current_nodes)\n",
    "\n",
    "\n",
    "\n",
    "            greedy_weight = compute_greedy_matching_weight(i, matrices[i], masks[i], current_nodes, random_match = False)\n",
    "\n",
    "            print(f\"max weight: {max_weight} predicted weight: {preds_weight}, greedy weight: {greedy_weight}\")\n",
    "\n",
    "            # assert preds_weight <= max_weight\n",
    "            # assert greedy_weight <= max_weight\n",
    "\n",
    "            greedy_accuracy += greedy_weight / max_weight\n",
    "            pred_accuracy += preds_weight / max_weight\n",
    "\n",
    "            count_non_zero_matchings += 1\n",
    "\n",
    "\n",
    "\n",
    "    return pred_accuracy / count_non_zero_matchings, greedy_accuracy / count_non_zero_matchings\n",
    "\n",
    "\n",
    "def compute_matching_weight_from_matching(A, mask, matching, predicted = False):\n",
    "    matching_weight = 0\n",
    "    matched = set()\n",
    "    # m is the number of offline nodes, -1 to not count the no match node\n",
    "    m = int(np.sum(mask)) - 1\n",
    "    # n is the number of online nodes\n",
    "    online_mask = 1 - mask\n",
    "    n = int(np.sum(online_mask))\n",
    "    unmatched_node = m + n\n",
    "\n",
    "    #TODO remove, is not great but here for eval, need 0-valued edges to the unmatched node\n",
    "    A[unmatched_node, :] = 0\n",
    "    A[:, unmatched_node] = 0\n",
    "\n",
    "\n",
    "    for online_node in range(m, m+n):\n",
    "        match = int(matching[online_node])\n",
    "        if match != unmatched_node:\n",
    "            # If points to self => weight is 0\n",
    "            if online_node != match and match not in matched:\n",
    "                matching_weight += A[online_node, match]\n",
    "            if not predicted:\n",
    "                # Checking that a same offline node is not assigned twice if using opt\n",
    "                assert match not in matched\n",
    "            matched.add(match)\n",
    "\n",
    "    # print(f\"opt matching: {matching}\")\n",
    "\n",
    "    return matching_weight\n",
    "\n",
    "\n",
    "def compute_matching_weight_from_match_h(i, A, mask, predicted_hints, current_nodes):\n",
    "    matching_weight = 0\n",
    "    # m is the number of offline nodes, -1 to not count the no match node\n",
    "    m = int(np.sum(mask)) - 1\n",
    "    # n is the number of online nodes\n",
    "    online_mask = 1 - mask\n",
    "    n = int(np.sum(online_mask))\n",
    "    unmatched_node = m + n\n",
    "    matched = np.ones(A.shape[0])\n",
    "    matched[m:m+n] = 0\n",
    "\n",
    "    matching = np.arange(m+n+1)\n",
    "\n",
    "    #TODO remove, is not great but here for eval, need 0-valued edges to the unmatched node\n",
    "    A[unmatched_node, :] = 0\n",
    "    A[:, unmatched_node] = 0\n",
    "\n",
    "    for iter, iter_hint in enumerate(predicted_hints):\n",
    "        hint = iter_hint[\"match_h\"][i]\n",
    "        match = np.argmax(hint)\n",
    "        print(f\"match predicted: {match}\")\n",
    "        online_node = np.argmax(current_nodes[iter, i])\n",
    "        if np.sum(current_nodes[iter, i]) != 0 and  A[online_node, match] != 0:\n",
    "            # If not the case, we have reached the end of the hints for this instance (there can be more if other instances require more hints) but then current_nodes[iter, i] will be the all 0s vector\n",
    "            # Also if  A[online_node, greedy_match] is 0, we can equivalently say that the node isn't matched (and it avoids using up a match for nothing). Due to sparsity\n",
    "            if online_node != match:\n",
    "                matching_weight += A[online_node, match]\n",
    "            if match != unmatched_node:\n",
    "                # Checking that a same offline node is not assigned twice\n",
    "                assert matched[match] == 1\n",
    "                matched[match] = 0\n",
    "                matching[match] = online_node\n",
    "            matching[online_node] = match\n",
    "        # TODO remove Checking if the model isn't matching with a stupid node\n",
    "        # assert match < m\n",
    "\n",
    "\n",
    "    # print(f\"hint matching: {matching}\")\n",
    "    return matching_weight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_hint_matching_weight(i, A, mask, predicted_hints, current_nodes):\n",
    "    matching_weight = 0\n",
    "    # m is the number of offline nodes, -1 to not count the no match node\n",
    "    m = int(np.sum(mask)) - 1\n",
    "    # n is the number of online nodes\n",
    "    online_mask = 1 - mask\n",
    "    n = int(np.sum(online_mask))\n",
    "    unmatched_node = m + n\n",
    "    matched = np.ones(A.shape[0])\n",
    "    matched[m:m+n] = 0\n",
    "\n",
    "    matching = np.arange(m+n+1)\n",
    "\n",
    "    #TODO remove, is not great but here for eval, need 0-valued edges to the unmatched node\n",
    "    A[unmatched_node, :] = 0\n",
    "    A[:, unmatched_node] = 0\n",
    "\n",
    "    for iter, iter_hint in enumerate(predicted_hints):\n",
    "        hint = iter_hint[\"value_to_go_h\"][i]\n",
    "        # Shifting hints to be positive so that the maximum is always > 0 if there are still edges to match\n",
    "        shifted_hint = hint + abs(np.min(hint))\n",
    "        # print(shifted_hint / np.max(shifted_hint))\n",
    "        masked_hint = shifted_hint * matched\n",
    "        match = np.argmax(masked_hint)\n",
    "        # current_nodes[iter, i] is a one-hot encoding of the current online node\n",
    "        online_node = np.argmax(current_nodes[iter, i])\n",
    "        if np.sum(current_nodes[iter, i]) != 0 and  A[online_node, match] != 0:\n",
    "            # If not the case, we have reached the end of the hints for this instance (there can be more if other instances require more hints) but then current_nodes[iter, i] will be the all 0s vector\n",
    "            # Also if  A[online_node, greedy_match] is 0, we can equivalently say that the node isn't matched (and it avoids using up a match for nothing). Due to sparsity\n",
    "            if online_node != match:\n",
    "                matching_weight += A[online_node, match]\n",
    "            if match != unmatched_node:\n",
    "                # Checking that a same offline node is not assigned twice\n",
    "                assert matched[match] == 1\n",
    "                matched[match] = 0\n",
    "                matching[match] = online_node\n",
    "            matching[online_node] = match\n",
    "        # TODO remove Checking if the model isn't matching with a stupid node\n",
    "        # assert match < m\n",
    "\n",
    "\n",
    "    # print(f\"hint matching: {matching}\")\n",
    "\n",
    "    return matching_weight\n",
    "\n",
    "\n",
    "def compute_greedy_matching_weight(i, A, mask, current_nodes, random_match = False):\n",
    "    matching_weight = 0\n",
    "    matched = np.ones(A.shape[0])\n",
    "    # m is the number of offline nodes, -1 to not count the no match node\n",
    "    m = int(np.sum(mask)) - 1\n",
    "    # n is the number of online nodes\n",
    "    online_mask = 1 - mask\n",
    "    n = int(np.sum(online_mask))\n",
    "    unmatched_node = m + n\n",
    "    matched[m:m+n] = 0\n",
    "\n",
    "    matching = np.arange(m+n+1)\n",
    "\n",
    "    #TODO remove, is not great but here for eval, need 0-valued edges to the unmatched node\n",
    "    A[unmatched_node, :] = 0\n",
    "    A[:, unmatched_node] = 0\n",
    "\n",
    "    # current_nodes shape is iteration x samples x nodes\n",
    "    for iter in range(current_nodes.shape[0]):\n",
    "        # current_nodes[iter, i] is a one-hot encoding of the current online node\n",
    "        online_node = np.argmax(current_nodes[iter, i])\n",
    "        possible_matches = A[online_node, :] * matched\n",
    "\n",
    "        if random_match:\n",
    "            choices = np.arange(m+n+1)[mask == 1]\n",
    "            greedy_match = np.random.choice(choices)\n",
    "        else:\n",
    "            greedy_match = np.argmax(possible_matches)\n",
    "\n",
    "\n",
    "        if np.sum(current_nodes[iter, i]) != 0 and possible_matches[greedy_match] != 0:\n",
    "            # If not the case, we have reached the end of the hints for this instance (there can be more if other instances require more hints) but then current_nodes[iter, i] will be the all 0s vector\n",
    "            # Also if possible_matches[greedy_match] is 0, we can equivalently say that the node isn't matched (and it avoids using up a match for nothing). Due to sparsity\n",
    "            if online_node != greedy_match:\n",
    "                matching_weight += A[online_node, greedy_match]\n",
    "            if greedy_match != unmatched_node:\n",
    "                # Checking that a same offline node is not assigned twice\n",
    "                assert matched[greedy_match] == 1\n",
    "                matched[greedy_match] = 0\n",
    "                matching[greedy_match] = online_node\n",
    "            matching[online_node] = greedy_match\n",
    "            # TODO remove Checking if doesn't do something stupid (this should have weight 0)\n",
    "            assert greedy_match < m\n",
    "\n",
    "    # print(f\"greedy matching: {matching}\")\n",
    "\n",
    "    return matching_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "test_feedback = next(test_sampler)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 1.7282347637124968 predicted weight: 0, greedy weight: 1.5924672515305591\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.8167674621222405 predicted weight: 0, greedy weight: 1.6082363686321732\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.516411003995997 predicted weight: 0, greedy weight: 1.8535205493567268\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 1.4370672667245779 predicted weight: 0, greedy weight: 1.7110854265254556\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7430658361024793 predicted weight: 0, greedy weight: 1.7185031938618915\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.6646607019011 predicted weight: 0, greedy weight: 1.6971266380507437\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.478349695838811 predicted weight: 0, greedy weight: 2.1102598736910902\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 1.7282347637124968 predicted weight: 0, greedy weight: 1.5924672515305591\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.5166094454145487 predicted weight: 0, greedy weight: 1.2053643451922684\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.3580126161511066 predicted weight: 0, greedy weight: 2.352558595373877\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.8167674621222405 predicted weight: 0, greedy weight: 1.6082363686321732\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.0304944421671185 predicted weight: 0, greedy weight: 1.1640894332599268\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.050000843768986 predicted weight: 0, greedy weight: 1.875359242756759\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7430658361024793 predicted weight: 0, greedy weight: 1.7185031938618915\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7422382244099737 predicted weight: 0, greedy weight: 2.212433336708547\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7430658361024793 predicted weight: 0, greedy weight: 1.7185031938618915\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7422382244099737 predicted weight: 0, greedy weight: 2.212433336708547\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.4137485306623705 predicted weight: 0, greedy weight: 1.5926783584246569\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.262133712201822 predicted weight: 0, greedy weight: 1.5169167904806755\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.050000843768986 predicted weight: 0, greedy weight: 1.875359242756759\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.794522714455768 predicted weight: 0, greedy weight: 2.1840381641304316\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.563880477944484 predicted weight: 0, greedy weight: 2.0230832894754687\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 1.6838350561544821 predicted weight: 0, greedy weight: 1.2948638710065206\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.079030180843182 predicted weight: 0, greedy weight: 1.5587568558279188\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.8167674621222405 predicted weight: 0, greedy weight: 1.6082363686321732\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 1.6838350561544821 predicted weight: 0, greedy weight: 1.2948638710065206\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.478349695838811 predicted weight: 0, greedy weight: 2.1102598736910902\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.355961953827908 predicted weight: 0, greedy weight: 2.355961953827908\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.0589199747714293 predicted weight: 0, greedy weight: 0.8852761346068887\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.7422382244099737 predicted weight: 0, greedy weight: 2.212433336708547\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.516411003995997 predicted weight: 0, greedy weight: 1.8535205493567268\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.3072604993962536 predicted weight: 0, greedy weight: 0.7976166889063071\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.4137485306623705 predicted weight: 0, greedy weight: 1.5926783584246569\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.4465436643145133 predicted weight: 0, greedy weight: 1.2395562644672198\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.1508265155807713 predicted weight: 0, greedy weight: 1.3631341478856491\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.079030180843182 predicted weight: 0, greedy weight: 1.5587568558279188\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.3574584644698175 predicted weight: 0, greedy weight: 1.307386987222701\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.8167674621222405 predicted weight: 0, greedy weight: 1.6082363686321732\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.6357964162242116 predicted weight: 0, greedy weight: 1.246493347657966\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "match predicted: 18\n",
      "max weight: 2.5718040219059346 predicted weight: 0, greedy weight: 1.4351175261405043\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.0, 0.7102440164429182)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, hints = model.predict(rng_key, test_feedback.features, return_hints = True)\n",
    "matching_value(test_feedback, hints, predictions, predict_match_h = True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([10.,  5.,  3.,  2., 18.,  1.,  6.,  7., 18.,  0.,  0., 11., 12.,\n       13., 14., 15., 16., 17., 18.], dtype=float32)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['match'].data[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([ 5.256347  ,  5.3603277 ,  2.412511  ,  0.76202863,  0.32679403,\n        0.4426093 , -0.7362897 , -0.73782516,  0.33354574,  0.37478045,\n        0.35014975, -0.72401756, -0.69578147, -0.654595  , -0.66573054,\n       -0.57426596, -0.55346304, -0.56289846,  6.020763  ], dtype=float32)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hints[0]['match_h'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "[DataPoint(name=\"value_to_go_h\",\tlocation=node,\ttype=scalar,\tdata=Array(9, 40, 19)),\n DataPoint(name=\"L_h\",\tlocation=node,\ttype=mask,\tdata=Array(9, 40, 19)),\n DataPoint(name=\"match_h\",\tlocation=node,\ttype=mask_one,\tdata=Array(9, 40, 19)),\n DataPoint(name=\"modified_node\",\tlocation=node,\ttype=mask_one,\tdata=Array(9, 40, 19))]"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.features.hints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.27700264, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.94055817])"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter = 3\n",
    "test_feedback.features.hints[0].data[iter, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1.])"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.features.hints[2].data[iter, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "75"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(mat[8:16] == 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "61"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.sum(mat[8:16] != 0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.89949414, 0.98475698,\n        0.60281735, 0.72707501, 0.1797913 , 0.5798067 , 0.29400526,\n        0.        , 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.32709095, 0.64599815,\n        0.46296552, 0.68987385, 0.33884224, 0.        , 0.84047621,\n        0.59821317, 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.62142034,\n        0.26787452, 0.97212067, 0.54769404, 0.73009603, 0.        ,\n        0.        , 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.90102657, 0.        ,\n        0.98141306, 0.55263826, 0.33889225, 0.17873712, 0.        ,\n        0.62468549, 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.60437317, 0.21586567,\n        0.35742596, 0.8597035 , 0.37604759, 0.58835736, 0.64883588,\n        0.        , 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.45413501, 0.34183565,\n        0.8207589 , 0.51553393, 0.        , 0.97556373, 0.06374633,\n        0.62164691, 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.46289927, 0.66502509,\n        0.32280696, 0.18552563, 0.        , 0.        , 0.96019446,\n        0.00149684, 1.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.02496784, 0.64427653, 0.43083714, 0.20751935,\n        0.78186288, 1.        ],\n       [0.89949414, 0.32709095, 0.        , 0.90102657, 0.60437317,\n        0.45413501, 0.46289927, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.98475698, 0.64599815, 0.62142034, 0.        , 0.21586567,\n        0.34183565, 0.66502509, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.60281735, 0.46296552, 0.26787452, 0.98141306, 0.35742596,\n        0.8207589 , 0.32280696, 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.72707501, 0.68987385, 0.97212067, 0.55263826, 0.8597035 ,\n        0.51553393, 0.18552563, 0.02496784, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.1797913 , 0.33884224, 0.54769404, 0.33889225, 0.37604759,\n        0.        , 0.        , 0.64427653, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.5798067 , 0.        , 0.73009603, 0.17873712, 0.58835736,\n        0.97556373, 0.        , 0.43083714, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.29400526, 0.84047621, 0.        , 0.        , 0.64883588,\n        0.06374633, 0.96019446, 0.20751935, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [0.        , 0.59821317, 0.        , 0.62468549, 0.        ,\n        0.62164691, 0.00149684, 0.78186288, 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        ],\n       [1.        , 1.        , 1.        , 1.        , 1.        ,\n        1.        , 1.        , 1.        , 1.        , 1.        ,\n        1.        , 1.        , 1.        , 1.        , 1.        ,\n        1.        , 1.        ]])"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.features.inputs[1].data[3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "[DataPoint(name=\"value_to_go_h\",\tlocation=node,\ttype=scalar,\tdata=Array(7, 40, 17)),\n DataPoint(name=\"L_h\",\tlocation=node,\ttype=mask,\tdata=Array(7, 40, 17)),\n DataPoint(name=\"match_h\",\tlocation=node,\ttype=pointer,\tdata=Array(7, 40, 17)),\n DataPoint(name=\"modified_node\",\tlocation=node,\ttype=mask_one,\tdata=Array(7, 40, 17))]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.features.hints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([-2.4598014, -2.433341 , -2.343672 , -2.4668386, -2.469148 ,\n       -2.4711394, -2.472333 , -2.4693463, -1.9480118, -1.7099818,\n       -1.8171515, -2.936937 , -2.936448 , -2.9389527, -2.9396846,\n       -2.0308576, -2.378499 ], dtype=float32)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hints[5][\"modified_node\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting test generation\n",
      "finished test generation\n",
      "Bypassing training\n"
     ]
    },
    {
     "data": {
      "text/plain": "[({'num_samples': 100,\n   'batch_size': 32,\n   'schematics': [{'generator': 'ER',\n     'proportion': 1,\n     'length': 64,\n     'kwargs': {'low': 0, 'high': 0.001, 'weighted': True}}]},\n  {'num_samples': 10,\n   'batch_size': 10,\n   'schematics': [{'generator': 'ER',\n     'proportion': 1,\n     'length': 1000,\n     'kwargs': {'p': 0.1, 'low': 0, 'high': 1, 'weighted': True}}]},\n  (0.8577524175395072, 0.9537646702986899))]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def variation_testing(train_sampler_spec, test_sampler_spec, epochs = 300, model = None, bypass_training = False):\n",
    "    if model is None and bypass_training:\n",
    "        print(\"Need a model to bypass training\")\n",
    "        return\n",
    "\n",
    "    matching_values = []\n",
    "    for train_param, test_param in zip(train_sampler_spec, test_sampler_spec):\n",
    "        # test_param['num_samples'] = 40\n",
    "        # test_param['batch_size'] = 40\n",
    "        # schematics = test_param['schematics']\n",
    "        # schematics[0]['length'] = 1000\n",
    "        # test_param['schematics'] = schematics\n",
    "\n",
    "        print(\"starting test generation\")\n",
    "        test_sampler, _ = samplers(test_param)\n",
    "        print(\"finished test generation\")\n",
    "\n",
    "        if not bypass_training:\n",
    "            train_sampler, spec = samplers(train_param)\n",
    "            model = define_model(spec, train_sampler, model = \"mpnn\")\n",
    "            train(model, epochs, train_sampler, test_sampler)\n",
    "        else:\n",
    "            print(\"Bypassing training\")\n",
    "\n",
    "        test_feedback = next(test_sampler)\n",
    "        predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "        accuracy = matching_value(test_feedback, predictions, partial = False, match_rest = False, opt_scipy = True)\n",
    "\n",
    "        matching_values.append((train_param, test_param, accuracy))\n",
    "    return model, matching_values\n",
    "\n",
    "\n",
    "weight_params = [{\"low\": 0, \"high\": 0.001},\n",
    "                 {\"low\": 1, \"high\": 1.001},\n",
    "                 {\"low\": 1, \"high\": 1.1},\n",
    "                 {\"low\": 1, \"high\": 2},\n",
    "                 {\"low\": 0, \"high\": 0.1},\n",
    "                 {\"low\": 0, \"high\": 1},\n",
    "                 # {\"low\": 0, \"high\": 10},\n",
    "                 # {\"low\": 0, \"high\": 100},\n",
    "                 # {\"low\": 50, \"high\": 200},\n",
    "                 # {\"low\": 500, \"high\": 2000},\n",
    "                 # {\"low\": 5000, \"high\": 20000}\n",
    "                 ]\n",
    "\n",
    "train_sampler_spec = [\n",
    "    {\n",
    "        'num_samples': 100, 'batch_size': 32,\n",
    "        'schematics':  [\n",
    "            {\n",
    "                'generator':  'ER',\n",
    "                'proportion': 1,\n",
    "                'length':     64,\n",
    "                'kwargs':     {'low': 0, 'high': 0.001, 'weighted': True}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "test_sampler = [\n",
    "    {\n",
    "        'num_samples': 10, 'batch_size': 10,\n",
    "        'schematics':  [\n",
    "            {\n",
    "                'generator':  'ER',\n",
    "                'proportion': 1,\n",
    "                'length':     1000,\n",
    "                'kwargs':     {'p': 0.1, 'low': 0, 'high': 1, 'weighted': True}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "length_training = [{\"generator\": \"ER\"}]\n",
    "length_testing = [{\"generator\": \"ER\", \"length\": 1000, \"p\": 0.01}]\n",
    "\n",
    "model, results = variation_testing(train_sampler_spec, copy.deepcopy(test_sampler), model = model,\n",
    "                                   bypass_training = True)\n",
    "\n",
    "results\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# import copy\n",
    "# model2 = copy.deepcopy(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ER p=0.25, 100 8x8 train and 40 32x32 test => 0.94 in 100 iterations\n",
    "\n",
    "BA param=3, 100 8x8 train and 40 32x32 test => 0.97 in 100 iterations\n",
    "\n",
    "BA param=5, 100 8x8 train and 40 32x32 test => 0.95 in 100 iterations (0.951 in 200 so has pretty much converged after 100)\n",
    "\n",
    "BA param=7, 100 8x8 train and 40 32x32 test => 0.946 in 100 iterations\n",
    "\n",
    "#### Cross training\n",
    "BA param=7 to BA param=3\n",
    "\n",
    "BA param=7 to ER p=0.25 0.946 with BA to 0.939 with ER (same as if trained only on BA)\n",
    "\n",
    "ER p=0.25 to BA param=3 went from 0.939 with ER to 0.967 with BA (BA param 3 was 0.97 so basically nothing lost)\n",
    "\n",
    "#### Weight variations\n",
    "Uniform\n",
    "* 0,0.001 -> 0.928\n",
    "* 1,1.001 -> 0.962\n",
    "* 0,0.1 -> 0.931\n",
    "* 0,10 -> 0.883\n",
    "* 0,100 -> 0.77\n",
    "* 50, 200 -> 0.72\n",
    "* 500, 2000 -> 0.69\n",
    "* 5000, 20000 -> 0.7\n",
    "\n",
    "Normal:\n",
    "Basically same.\n",
    "\n",
    "Gumbel\n",
    "* 0,0.001 -> 0.323\n",
    "* 1,1.001 -> 0.849\n",
    "* 0,0.1 -> 0.498\n",
    "* 5,10 -> 0.82\n",
    "* 5,100 -> 0.8\n",
    "\n",
    "#### Weight cross training\n",
    "Train ER p=0.25 unif 0,1:\n",
    "* 0,0.001 -> 0.948\n",
    "* 1,1.001 -> 0.967\n",
    "* 0,0.1 -> 0.916\n",
    "* 0,10 -> 0.86\n",
    "* 0,100 -> 0.75\n",
    "* 50, 200 -> 0.72\n",
    "* 500, 2000 -> 0.72\n",
    "* 5000, 20000 -> 0.69\n",
    "\n",
    "=> Seems to weight generalize quite well. Actually even better because basically no statistical difference with if we trained separately.\n",
    "\n",
    "Train normal 5000, 20000:\n",
    "* 0, 0.001 -> 0.39 (maybe it's the large to small that was a problem here? Also those values make little sense for a normal RV)\n",
    "\n",
    "Other direction train normal 0, 0.001 (got to 0.78):\n",
    "* 5000, 20000 -> 0.76\n",
    "\n",
    "=> small to large seems better\n",
    "\n",
    "\n",
    "#### Larger graphs\n",
    "Same training\n",
    "ER p=0.25 8x8 train:\n",
    "* 100x100 test goes to 0.88\n",
    "* 200x200 goes to 0.63 (only 12 prediction mismatches though)\n",
    "* 200x200 p=0.3 =>\n",
    "* 250x250 => 0.9448 (BUT p=0.1 to not kill my computer)\n",
    "*\n",
    "Try this but 16x16 train\n",
    "\n",
    "#### RIDESHARE\n",
    "8x8 train,\n",
    "* 32x32 test => 0.96\n",
    "* 50x50 test => 0.96\n",
    "* 100x100 test => 0.938\n",
    "* 250x250 test => 0.9\n",
    "\n",
    "#### Double max\n",
    "8x8 train 32x23 test\n",
    "300 iterations gets us to 0.93 as normal max (though normal max takes 100 iterations to get there), 600 iterations gets us to 0.965\n",
    "==> Testing single max on 600 iterations => 0.956\n",
    "==> Testing single max with 64 hidden dim embeddings on 600 iterations 0.96 (already in 200) (seeing if gain is only from more parameters or if double max is actually more aligned)\n",
    "\n",
    "Conclusion, it was mainly due to more iterations + some amount of more parameters but only 1% so probably not statistically significant.\n",
    "\n",
    "#### Training with scaling\n",
    "Train/test with 5000, 200000 weights ==> 0.76 accuracy\n",
    "But if normalize 0, 1 on training (or just train on normalized) ==> 0.91 (same acc as had train/testing on normalized)\n",
    "\n",
    "#### More weight scales training\n",
    "300 epochs for all, 4x4 train, 32x32 test\n",
    "* 0, 1: 0.946, 0.917\n",
    "* 1, 1.01: 0.993, 0.970\n",
    "* 1, 1.001: 0.956, 0.976\n",
    "* 1, 1.1: 0.989, 0.972\n",
    "* 1, 1.2: 0.986, 0.958\n",
    "* 1, 1.5: 0.966, 0.949\n",
    "* 1, 2: 0.957, 0.939\n",
    "* 2, 2.1: 0.9927, 0.9757\n",
    "* 10, 10.001: 0.4, 0.97\n",
    "Realization: shifting just doesn't makes sense (val + 1000) / (opt + 1000) > val / opt\n",
    "\n",
    "==> find the best range\n",
    "* 0, 0.001: 0.79, 0.929\n",
    "* 0, 0.01: 0.79, 0.922\n",
    "* 0, 0.1: 0.76, 0.934\n",
    "* 0, 1: 0.94, 0.9334\n",
    "* 0, 10: 0.897, 0.928\n",
    "* 0, 100: 0.7, 0.93\n",
    "\n",
    "### Teacher forcing\n",
    "1.0:  100 epochs => 0.92   | 200 epochs => 0.968\n",
    "0.75: 100 epochs => 0.956 | 200 epochs => 0.959 | 300 => 0.957 | 400 => 0.966 | 500 => 0.954 | 600 => 0.964\n",
    "0.5: 100 epochs => 0.943 | 200 => 0.943 | 300 => 0.952 | 400 => 0.938 | 500 => 0.928 | 0.953\n",
    "0.25: 100 => 0.923 | 200 => 0.935 | 300 => 0.932 | 400 => 0.936 | 500 => 0.948 | 600 => 0.94\n",
    "0: 100 => 0.9 | 200 => 0.977 | 300 => 0.937 | 400 => 0.924 | 500 => 0.923 | 600 => 0.958 | 800 => 0.98\n",
    "\n",
    "### GMPNN\n",
    "MPNN: 100 => 0.92  | 200 => 0.968\n",
    "GMPNN 100 => 0.956 | 200 => 0.957 | 300 => 0.948 | 400 => 0.935\n",
    "\n",
    "### Larger graphs\n",
    "GPMNN with 16 node (8x8) graphs as training\n",
    "100 => 0.965 | 200 => 0.968 | 300 => 0.969 | 400 => 0.971 | 500 => 0.972 | 600 => 0.971 | 700 => 0.981 | 800 => 0.973\n",
    "\n",
    "### Train on larger\n",
    "GPMNN with 16 node (8x8) graphs as training\n",
    "100 => 0.965 | 200 => 0.968 | 300 => 0.969 | 400 => 0.971 | 500 => 0.972 | 600 => 0.971 | 700 => 0.981 | 800 => 0.973\n",
    "\n",
    "### Soft pointers\n",
    "\n",
    "\n",
    "#### Cross training with p value for ER\n",
    "GMPNN 400 epochs\n",
    "ER\n",
    "0.05: 0.87, 0.96\n",
    "0.1: 0.76, 0.94\n",
    "0.2: 0.75, 0.91\n",
    "0.5: 0.93, 0.93\n",
    "0.75: 0.94, 0.95\n",
    "1: 0.88, 0.96\n",
    "\n",
    "Compare to if learned directly: (train on those parameters then test i.e. no cross-training) + is MPNN, not GMPNN\n",
    "0.05: 0.95, 0.96\n",
    "0.1: 0.86, 0.93\n",
    "0.2: 0.7, 0.9\n",
    "0.5: 0.9, 0.94\n",
    "0.75: 0.93, 0.95\n",
    "1: 0.85, 0.95\n",
    "\n",
    "Already got ER + Rideshare generalization + BA generalization to other parameters to larger graphs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary results\n",
    "random permutation/matching: 0.18\n",
    "\n",
    "MPNN:\n",
    "learned predictions: 0.67\n",
    "\n",
    "GAT:\n",
    "learned predictions: 0.72\n",
    "\n",
    "Got better with double ended predictions\n",
    "\n",
    "Partial: 0.64 while greedy was doing about 0.92 on the same instance. Main reason seems to be that max weight is around 1.5 => can get at most 2/3 OPT\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counting the number of matching constraints violated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of edges contradicting matching: 12.2\n"
     ]
    }
   ],
   "source": [
    "# For two-way\n",
    "def count_mismatches_two_way(predictions):\n",
    "    count = 0\n",
    "    data = predictions[\"match\"].data\n",
    "    nb_graphs = data.shape[0]\n",
    "    for datapoint in range(data.shape[0]):\n",
    "        for i in range(32):\n",
    "            owner = data[datapoint][i]\n",
    "            good = data[datapoint][int(owner)]\n",
    "            if good != i:\n",
    "                count += 1\n",
    "    print(f\"average number of edges contradicting matching: {count / nb_graphs}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of edges contradicting matching: 0.4\n"
     ]
    }
   ],
   "source": [
    "# For self-loops\n",
    "def count_mismatches_self_loop(predictions):\n",
    "    count = 0\n",
    "    data = predictions[\"match\"].data\n",
    "    nb_graphs = data.shape[0]\n",
    "    for datapoint in range(data.shape[0]):\n",
    "        owners = set(np.array(data[datapoint][32:64]))\n",
    "        count += 32 - len(owners)\n",
    "    print(f\"average number of edges contradicting matching: {count / nb_graphs}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([2, 3])\n",
    "print(np.concatenate((a, b)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
