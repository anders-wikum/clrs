{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import clrs\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pprint\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ],
   "metadata": {
    "id": "2MzxRB1X7hRs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eee4d47e-b689-497b-e9b5-021121cac2b7"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_sampler, spec = clrs.build_sampler(\n",
    "    name='bipartite_matching',\n",
    "    num_samples=100,\n",
    "    length=16,\n",
    "    weighted=True) # number of nodes\n",
    "\n",
    "test_sampler, spec = clrs.build_sampler(\n",
    "    name='bipartite_matching',\n",
    "    num_samples=100,\n",
    "    length=64,\n",
    "    weighted=True) # testing on much larger\n",
    "# TODO how do you know aren't generating same graphs? (well not possible here since different size but in general?)\n",
    "\n",
    "pprint.pprint(spec) # spec is the algorithm specification, all the probes\n",
    "\n",
    "def _iterate_sampler(sampler, batch_size):\n",
    "  while True:\n",
    "    yield sampler.next(batch_size)\n",
    "\n",
    "train_sampler = _iterate_sampler(train_sampler, batch_size=32)\n",
    "test_sampler = _iterate_sampler(test_sampler, batch_size=100) # full batch for the test set\n"
   ],
   "metadata": {
    "id": "OEo_Gj1j3Z6M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ef53c51-9bc2-4a49-b4cf-592a32dfa5b7"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ('input', 'edge', 'scalar'),\n",
      " 'A_h': ('hint', 'edge', 'scalar'),\n",
      " 'adj': ('input', 'edge', 'mask'),\n",
      " 'adj_h': ('hint', 'edge', 'mask'),\n",
      " 'd': ('hint', 'node', 'scalar'),\n",
      " 'in_matching': ('output', 'edge', 'mask'),\n",
      " 'in_matching_h': ('hint', 'edge', 'mask'),\n",
      " 'msk': ('hint', 'node', 'mask'),\n",
      " 'phase': ('hint', 'graph', 'mask'),\n",
      " 'pi': ('hint', 'node', 'pointer'),\n",
      " 'pos': ('input', 'node', 'scalar'),\n",
      " 's': ('input', 'node', 'mask_one'),\n",
      " 't': ('input', 'node', 'mask_one'),\n",
      " 'u': ('hint', 'node', 'mask_one')}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Bipartite graph is weighted\n",
    "next(train_sampler).features.inputs[1].data[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "110Yfa4D-GgS",
    "outputId": "b51eda7a-28ff-4b9e-ab0e-3147281adc83"
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.40309255, 0.82758018, 0.91295964, 0.30944842,\n        0.0315634 , 0.06428168, 0.00208438, 0.65677349, 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.42245016, 0.        , 0.20672695, 0.        ,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.38261076, 0.        , 0.        ,\n        0.        , 0.36597594, 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.71865507,\n        0.        , 0.        , 0.        , 0.        , 0.14134505,\n        0.        , 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.33136518, 0.        ,\n        0.34346674, 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.28762282, 0.        , 0.        , 0.        , 0.70271622,\n        0.        , 0.58989   , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.52365393,\n        0.28324547, 0.83153318, 0.        , 0.35304073, 0.07280118,\n        0.        , 0.51891878, 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.09606921, 0.        , 0.        ,\n        0.92983224, 0.        , 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.35777346, 0.        , 0.        , 0.60452033,\n        0.        , 0.09563371, 0.        ],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.17506772],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.60483603],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.27063322],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.72796982],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00714165],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.94269093],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.63264653],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.93193171],\n       [0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        ]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "processor_factory = clrs.get_processor_factory('mpnn', use_ln=True, nb_triplet_fts=0) #use_ln => use layer norm \n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory, # contains the processor_factory\n",
    "    hidden_dim=32,\n",
    "    encode_hints=True,\n",
    "    decode_hints=True,\n",
    "    #decode_diffs=False,\n",
    "    #hint_teacher_forcing_noise=1.0,\n",
    "    hint_teacher_forcing=1.0,\n",
    "    use_lstm=False,\n",
    "    learning_rate=0.001,\n",
    "    checkpoint_path='/tmp/checkpt',\n",
    "    freeze_processor=False, # Good for post step\n",
    "    dropout_prob=0.0,\n",
    ")\n",
    "\n",
    "dummy_trajectory = next(train_sampler) # jax needs a trajectory that is plausible looking to init\n",
    "\n",
    "model = clrs.models.BaselineModel(\n",
    "    spec=spec,\n",
    "    dummy_trajectory=dummy_trajectory,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "model.init(dummy_trajectory.features, 1234) # 1234 is a random seed"
   ],
   "metadata": {
    "id": "L-p0jOCq5sPV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "step = 0\n",
    "\n",
    "while step <= 200:\n",
    "  feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "  rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "  cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "  rng_key = new_rng_key\n",
    "  if step % 10 == 0:\n",
    "    predictions_val, _ = model.predict(rng_key, feedback.features)\n",
    "    out_val = clrs.evaluate(feedback.outputs, predictions_val)\n",
    "    predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "    out = clrs.evaluate(test_feedback.outputs, predictions)\n",
    "    print(f'step = {step} | loss = {cur_loss} | val_acc = {out_val[\"score\"]} | test_acc = {out[\"score\"]}') # here, val accuracy is actually training accuracy, not great but is example\n",
    "  step += 1"
   ],
   "metadata": {
    "id": "3pSKQ2wi62Br",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1acd203-e256-4f39-e059-9c7e55942a87"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step = 0 | loss = 18.544353485107422 | val_acc = 0.5307644605636597 | test_acc = 0.28374454379081726\n",
      "step = 10 | loss = 8.695533752441406 | val_acc = 0.5333715081214905 | test_acc = 0.3007984757423401\n",
      "step = 20 | loss = 6.970330238342285 | val_acc = 0.47899776697158813 | test_acc = 0.3936541974544525\n",
      "step = 30 | loss = 6.004898548126221 | val_acc = 0.6611765027046204 | test_acc = 0.41111698746681213\n",
      "step = 40 | loss = 5.4687700271606445 | val_acc = 0.577235758304596 | test_acc = 0.3613807260990143\n",
      "step = 50 | loss = 4.589337348937988 | val_acc = 0.5734208226203918 | test_acc = 0.3562544584274292\n",
      "step = 60 | loss = 4.119411468505859 | val_acc = 0.5963488817214966 | test_acc = 0.27703341841697693\n",
      "step = 70 | loss = 3.780219316482544 | val_acc = 0.6741573214530945 | test_acc = 0.3141278624534607\n",
      "step = 80 | loss = 3.339991331100464 | val_acc = 0.7116518616676331 | test_acc = 0.2799810469150543\n",
      "step = 90 | loss = 3.2398462295532227 | val_acc = 0.7173252105712891 | test_acc = 0.44405367970466614\n",
      "step = 100 | loss = 2.8373141288757324 | val_acc = 0.7203826308250427 | test_acc = 0.4553292691707611\n",
      "step = 110 | loss = 2.5996336936950684 | val_acc = 0.7233722805976868 | test_acc = 0.4566614329814911\n",
      "step = 120 | loss = 2.3135926723480225 | val_acc = 0.7008742094039917 | test_acc = 0.4998120963573456\n",
      "step = 130 | loss = 1.9699351787567139 | val_acc = 0.620362401008606 | test_acc = 0.508194625377655\n",
      "step = 140 | loss = 1.8527984619140625 | val_acc = 0.6950459480285645 | test_acc = 0.4389466941356659\n",
      "step = 150 | loss = 1.5929652452468872 | val_acc = 0.7098674178123474 | test_acc = 0.4486212730407715\n",
      "step = 160 | loss = 1.3540239334106445 | val_acc = 0.6820765137672424 | test_acc = 0.45171669125556946\n",
      "step = 170 | loss = 1.211611032485962 | val_acc = 0.6756673455238342 | test_acc = 0.4067860543727875\n",
      "step = 180 | loss = 1.2152010202407837 | val_acc = 0.6571508646011353 | test_acc = 0.38285744190216064\n",
      "step = 190 | loss = 0.9754116535186768 | val_acc = 0.6457046270370483 | test_acc = 0.34052759408950806\n",
      "step = 200 | loss = 0.8955589532852173 | val_acc = 0.5955555438995361 | test_acc = 0.2989889979362488\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "KErwB-7msBlB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
