{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import clrs\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pprint\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ],
   "metadata": {
    "id": "2MzxRB1X7hRs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eee4d47e-b689-497b-e9b5-021121cac2b7"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 20:15:50.541607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_sampler, spec = clrs.build_sampler(\n",
    "    name='auction_matching',\n",
    "    num_samples=100,\n",
    "    length=16,\n",
    "    weighted=True) # number of nodes\n",
    "\n",
    "test_sampler, spec = clrs.build_sampler(\n",
    "    name='auction_matching',\n",
    "    num_samples=40, # TODO set back to more\n",
    "    length=64,\n",
    "    weighted=True) # testing on much larger\n",
    "# TODO how do you know aren't generating same graphs? (well not possible here since different size but in general?)\n",
    "\n",
    "pprint.pprint(spec) # spec is the algorithm specification, all the probes\n",
    "\n",
    "def _iterate_sampler(sampler, batch_size):\n",
    "  while True:\n",
    "    yield sampler.next(batch_size)\n",
    "\n",
    "train_sampler = _iterate_sampler(train_sampler, batch_size=32)\n",
    "test_sampler = _iterate_sampler(test_sampler, batch_size=40) # full batch for the test set\n"
   ],
   "metadata": {
    "id": "OEo_Gj1j3Z6M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ef53c51-9bc2-4a49-b4cf-592a32dfa5b7"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ('input', 'edge', 'scalar'),\n",
      " 'adj': ('input', 'edge', 'mask'),\n",
      " 'buyers': ('input', 'node', 'mask'),\n",
      " 'in_queue': ('hint', 'node', 'mask'),\n",
      " 'owners': ('output', 'node', 'pointer'),\n",
      " 'owners_h': ('hint', 'node', 'pointer'),\n",
      " 'p': ('hint', 'node', 'scalar'),\n",
      " 'pos': ('input', 'node', 'scalar')}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Bipartite graph is weighted\n",
    "print(next(train_sampler).features.inputs[1].data[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "110Yfa4D-GgS",
    "outputId": "b51eda7a-28ff-4b9e-ab0e-3147281adc83"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13720626 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.92963277 0.         0.88031202 0.         0.53336933\n",
      "  0.         0.52068571 0.         0.         0.82835848 0.49224233\n",
      "  0.         0.         0.30007914 0.        ]\n",
      " [0.         0.         0.         0.38189772 0.         0.\n",
      "  0.         0.05240804 0.         0.         0.         0.4720396\n",
      "  0.53658954 0.         0.         0.        ]\n",
      " [0.         0.88031202 0.38189772 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40886447 0.\n",
      "  0.73795361 0.5591565  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.62631406 0.         0.51914184 0.88036373 0.79552802 0.33534672\n",
      "  0.         0.         0.06154556 0.80690847]\n",
      " [0.         0.53336933 0.         0.         0.         0.78045274\n",
      "  0.33451041 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.62631406 0.33451041\n",
      "  0.         0.63770593 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.52068571 0.05240804 0.         0.         0.\n",
      "  0.63770593 0.         0.         0.20012161 0.         0.\n",
      "  0.         0.27917222 0.         0.25052762]\n",
      " [0.13720626 0.         0.         0.         0.51914184 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.88036373 0.\n",
      "  0.         0.20012161 0.         0.         0.3664519  0.23687543\n",
      "  0.         0.56430396 0.         0.        ]\n",
      " [0.         0.82835848 0.         0.40886447 0.79552802 0.\n",
      "  0.         0.         0.         0.3664519  0.         0.\n",
      "  0.         0.40227672 0.         0.33653574]\n",
      " [0.         0.49224233 0.4720396  0.         0.33534672 0.\n",
      "  0.         0.         0.         0.23687543 0.         0.\n",
      "  0.49175524 0.11965681 0.39850905 0.13809487]\n",
      " [0.         0.         0.53658954 0.73795361 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.49175524\n",
      "  0.10021983 0.         0.         0.31720456]\n",
      " [0.         0.         0.         0.5591565  0.         0.\n",
      "  0.         0.27917222 0.         0.56430396 0.40227672 0.11965681\n",
      "  0.         0.         0.20692843 0.30813454]\n",
      " [0.         0.30007914 0.         0.         0.06154556 0.\n",
      "  0.         0.         0.         0.         0.         0.39850905\n",
      "  0.         0.20692843 0.68340342 0.        ]\n",
      " [0.         0.         0.         0.         0.80690847 0.\n",
      "  0.         0.25052762 0.         0.         0.33653574 0.13809487\n",
      "  0.31720456 0.30813454 0.         0.        ]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "processor_factory = clrs.get_processor_factory('mpnn', use_ln=True, nb_triplet_fts=0) #use_ln => use layer norm \n",
    "processor_factory = clrs.get_processor_factory('gat', use_ln=True, nb_heads = 4, nb_triplet_fts = 0)\n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory, # contains the processor_factory\n",
    "    hidden_dim=32,\n",
    "    encode_hints=True,\n",
    "    decode_hints=True,\n",
    "    #decode_diffs=False,\n",
    "    #hint_teacher_forcing_noise=1.0,\n",
    "    hint_teacher_forcing=1.0,\n",
    "    use_lstm=False,\n",
    "    learning_rate=0.001,\n",
    "    checkpoint_path='/tmp/checkpt',\n",
    "    freeze_processor=False, # Good for post step\n",
    "    dropout_prob=0.0,\n",
    ")\n",
    "\n",
    "dummy_trajectory = next(train_sampler) # jax needs a trajectory that is plausible looking to init\n",
    "\n",
    "model = clrs.models.BaselineModel(\n",
    "    spec=spec,\n",
    "    dummy_trajectory=dummy_trajectory,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "model.init(dummy_trajectory.features, 1234) # 1234 is a random seed"
   ],
   "metadata": {
    "id": "L-p0jOCq5sPV"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "step = 0\n",
    "\n",
    "while step <= 100:\n",
    "  feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "  rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "  cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "  rng_key = new_rng_key\n",
    "  if step % 10 == 0:\n",
    "    predictions_val, _ = model.predict(rng_key, feedback.features)\n",
    "    out_val = clrs.evaluate(feedback.outputs, predictions_val)\n",
    "    predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "    out = clrs.evaluate(test_feedback.outputs, predictions)\n",
    "    print(f'step = {step} | loss = {cur_loss} | val_acc = {out_val[\"score\"]} | test_acc = {out[\"score\"]}') # here, val accuracy is actually training accuracy, not great but is example\n",
    "  step += 1"
   ],
   "metadata": {
    "id": "3pSKQ2wi62Br",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1acd203-e256-4f39-e059-9c7e55942a87"
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0 | loss = 0.6523988246917725 | val_acc = 0.82421875 | test_acc = 0.790234386920929\n",
      "step = 10 | loss = 0.6065563559532166 | val_acc = 0.86328125 | test_acc = 0.762890636920929\n",
      "step = 20 | loss = 0.6038270592689514 | val_acc = 0.861328125 | test_acc = 0.7730469107627869\n",
      "step = 30 | loss = 0.6365153789520264 | val_acc = 0.845703125 | test_acc = 0.76953125\n",
      "step = 40 | loss = 0.591829240322113 | val_acc = 0.81640625 | test_acc = 0.7796875238418579\n",
      "step = 50 | loss = 0.6535412669181824 | val_acc = 0.849609375 | test_acc = 0.7671875357627869\n",
      "step = 60 | loss = 0.5626905560493469 | val_acc = 0.861328125 | test_acc = 0.780078113079071\n",
      "step = 70 | loss = 0.5786242485046387 | val_acc = 0.8203125 | test_acc = 0.775390625\n",
      "step = 80 | loss = 0.5910295248031616 | val_acc = 0.8203125 | test_acc = 0.783203125\n",
      "step = 90 | loss = 0.5957251787185669 | val_acc = 0.830078125 | test_acc = 0.7640625238418579\n",
      "step = 100 | loss = 0.5553303360939026 | val_acc = 0.806640625 | test_acc = 0.770312488079071\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# TODO verify code and check what it gives with random permutation\n",
    "def matching_value(samples, predictions):\n",
    "    features = samples.features\n",
    "    gt_matchings = samples.outputs[0].data\n",
    "    # inputs for the matrix A are at index 1 (see spec.py)\n",
    "    data = features.inputs[1].data\n",
    "    masks = features.inputs[3].data\n",
    "    pred_accuracy = 0\n",
    "\n",
    "    # Iterating over all the samples\n",
    "    for i in range(data.shape[0]):\n",
    "        max_weight = compute_matching_weight(i, data, masks, gt_matchings[i])\n",
    "\n",
    "        # TODO remove\n",
    "        predicted_matching = predictions[\"owners\"].data[i]\n",
    "        buyers_mask = masks[i]\n",
    "        n = int(np.sum(buyers_mask))\n",
    "        permutation = np.random.permutation(np.arange(np.sum(buyers_mask == 0)))\n",
    "        # predicted_matching = np.concatenate((np.zeros(n), permutation))\n",
    "        preds_weight = compute_matching_weight(i, data, masks, predicted_matching)\n",
    "        print(f\"max: {max_weight}, pred: {preds_weight}\")\n",
    "        assert preds_weight <= max_weight\n",
    "        pred_accuracy += preds_weight / max_weight\n",
    "\n",
    "    return pred_accuracy / data.shape[0]\n",
    "\n",
    "def compute_matching_weight(i, data, masks, matching):\n",
    "    matching_weight = 0\n",
    "    A = data[i]\n",
    "    buyers_mask = masks[i]\n",
    "    n = int(np.sum(buyers_mask))\n",
    "    consumers_mask = 1 - buyers_mask\n",
    "\n",
    "\n",
    "\n",
    "    # Only consider the matching values for consumers\n",
    "    matching = np.where(consumers_mask == 1, matching, -1)\n",
    "\n",
    "    for buyer in range(n):\n",
    "        if buyer in matching:\n",
    "            # If several goods point to the same buyer, keep the one with maximum weight\n",
    "            matching_weight += np.max(A[buyer, matching == buyer])\n",
    "\n",
    "    return matching_weight\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "test_feedback = next(test_sampler)\n",
    "predictions, _ = model.predict(rng_key, test_feedback.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 24.27956714466754, pred: 16.34168389134737\n",
      "max: 22.102475176188705, pred: 16.059375099667196\n",
      "max: 23.86077967779625, pred: 16.820780982633178\n",
      "max: 23.047660039579167, pred: 18.383731617695002\n",
      "max: 22.102475176188705, pred: 16.059375099667196\n",
      "max: 23.25031575548427, pred: 15.89369440318066\n",
      "max: 21.975819935846754, pred: 14.496811062052748\n",
      "max: 23.25031575548427, pred: 15.89369440318066\n",
      "max: 23.15032587271355, pred: 17.09720336740702\n",
      "max: 22.655820454391158, pred: 16.33835209746942\n",
      "max: 22.246620952133604, pred: 15.210615682279373\n",
      "max: 23.622342726948837, pred: 16.52460606280363\n",
      "max: 23.35910025981948, pred: 16.420581118740042\n",
      "max: 24.36949590014474, pred: 17.73089264444693\n",
      "max: 23.132478080934842, pred: 18.370195596097687\n",
      "max: 22.699991401473866, pred: 15.062203166478351\n",
      "max: 22.617621061457204, pred: 15.237357107627743\n",
      "max: 23.35910025981948, pred: 16.420581118740042\n",
      "max: 23.25031575548427, pred: 15.89369440318066\n",
      "max: 23.35910025981948, pred: 16.420581118740042\n",
      "max: 21.345776156289848, pred: 15.755853239865361\n",
      "max: 22.246620952133604, pred: 15.210615682279373\n",
      "max: 22.777766665355404, pred: 17.528180622926516\n",
      "max: 23.738737724130516, pred: 16.74483622388202\n",
      "max: 24.27956714466754, pred: 16.34168389134737\n",
      "max: 22.292652777498706, pred: 15.403859939925153\n",
      "max: 23.047660039579167, pred: 18.383731617695002\n",
      "max: 23.132478080934842, pred: 18.370195596097687\n",
      "max: 21.345776156289848, pred: 15.755853239865361\n",
      "max: 21.345776156289848, pred: 15.755853239865361\n",
      "max: 23.15032587271355, pred: 17.09720336740702\n",
      "max: 22.102475176188705, pred: 16.059375099667196\n",
      "max: 22.63755690844879, pred: 16.415587802351414\n",
      "max: 22.777766665355404, pred: 17.528180622926516\n",
      "max: 23.681605223367942, pred: 17.105623712040472\n",
      "max: 22.777766665355404, pred: 17.528180622926516\n",
      "max: 22.63755690844879, pred: 16.415587802351414\n",
      "max: 22.597014006649122, pred: 16.820668139303898\n",
      "max: 23.68270332897941, pred: 17.718335013431243\n",
      "max: 22.292652777498706, pred: 15.403859939925153\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7209796596579074"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_value(test_feedback, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary results\n",
    "random permutation/matching: 0.18\n",
    "\n",
    "MPNN:\n",
    "learned predictions: 0.67\n",
    "\n",
    "GAT:\n",
    "learned predictions: 0.72\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
