{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import clrs\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pprint\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ],
   "metadata": {
    "id": "2MzxRB1X7hRs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eee4d47e-b689-497b-e9b5-021121cac2b7"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:31:44.727536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_sampler, spec = clrs.build_sampler(\n",
    "    name='auction_matching',\n",
    "    num_samples=100,\n",
    "    length=16,\n",
    "    weighted=True) # number of nodes\n",
    "\n",
    "test_sampler, spec = clrs.build_sampler(\n",
    "    name='auction_matching',\n",
    "    num_samples=40, # TODO set back to more\n",
    "    length=64,\n",
    "    weighted=True) # testing on much larger\n",
    "# TODO how do you know aren't generating same graphs? (well not possible here since different size but in general?)\n",
    "\n",
    "pprint.pprint(spec) # spec is the algorithm specification, all the probes\n",
    "\n",
    "def _iterate_sampler(sampler, batch_size):\n",
    "  while True:\n",
    "    yield sampler.next(batch_size)\n",
    "\n",
    "train_sampler = _iterate_sampler(train_sampler, batch_size=32)\n",
    "test_sampler = _iterate_sampler(test_sampler, batch_size=40) # full batch for the test set\n"
   ],
   "metadata": {
    "id": "OEo_Gj1j3Z6M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5ef53c51-9bc2-4a49-b4cf-592a32dfa5b7"
   },
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ('input', 'edge', 'scalar'),\n",
      " 'adj': ('input', 'edge', 'mask'),\n",
      " 'buyers': ('input', 'node', 'mask'),\n",
      " 'in_queue': ('hint', 'node', 'mask'),\n",
      " 'owners': ('output', 'node', 'pointer'),\n",
      " 'owners_h': ('hint', 'node', 'pointer'),\n",
      " 'p': ('hint', 'node', 'scalar'),\n",
      " 'pos': ('input', 'node', 'scalar')}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "processor_factory = clrs.get_processor_factory('mpnn', use_ln=True, nb_triplet_fts=0) #use_ln => use layer norm \n",
    "# processor_factory = clrs.get_processor_factory('gat', use_ln=True, nb_heads = 4, nb_triplet_fts = 0)\n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory, # contains the processor_factory\n",
    "    hidden_dim=32,\n",
    "    encode_hints=True,\n",
    "    decode_hints=True,\n",
    "    #decode_diffs=False,\n",
    "    #hint_teacher_forcing_noise=1.0,\n",
    "    hint_teacher_forcing=1.0,\n",
    "    use_lstm=False,\n",
    "    learning_rate=0.001,\n",
    "    checkpoint_path='/tmp/checkpt',\n",
    "    freeze_processor=False, # Good for post step\n",
    "    dropout_prob=0.5,\n",
    ")\n",
    "\n",
    "dummy_trajectory = next(train_sampler) # jax needs a trajectory that is plausible looking to init\n",
    "\n",
    "model = clrs.models.BaselineModel(\n",
    "    spec=spec,\n",
    "    dummy_trajectory=dummy_trajectory,\n",
    "    **model_params\n",
    ")\n",
    "\n",
    "model.init(dummy_trajectory.features, 1234) # 1234 is a random seed"
   ],
   "metadata": {
    "id": "L-p0jOCq5sPV"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# No evaluation since we are postprocessing with soft: TO CHANGE -> baselines.py line 336 outs change hard to False\n",
    "step = 0\n",
    "\n",
    "while step <= 100:\n",
    "    feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "    rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "    cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "    rng_key = new_rng_key\n",
    "    if step % 10 == 0:\n",
    "        print(step)\n",
    "    step += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "step = 0\n",
    "\n",
    "while step <= 100:\n",
    "  feedback, test_feedback = next(train_sampler), next(test_sampler)\n",
    "  rng_key, new_rng_key = jax.random.split(rng_key) # jax needs new random seed at step\n",
    "  cur_loss = model.feedback(rng_key, feedback) # loss is contained in model somewhere\n",
    "  rng_key = new_rng_key\n",
    "  if step % 10 == 0:\n",
    "    predictions_val, _ = model.predict(rng_key, feedback.features)\n",
    "    out_val = clrs.evaluate(feedback.outputs, predictions_val)\n",
    "    predictions, _ = model.predict(rng_key, test_feedback.features)\n",
    "    out = clrs.evaluate(test_feedback.outputs, predictions)\n",
    "    print(f'step = {step} | loss = {cur_loss} | val_acc = {out_val[\"score\"]} | test_acc = {out[\"score\"]}') # here, val accuracy is actually training accuracy, not great but is example\n",
    "  step += 1"
   ],
   "metadata": {
    "id": "3pSKQ2wi62Br",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1acd203-e256-4f39-e059-9c7e55942a87"
   },
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m      9\u001B[0m   predictions_val, _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(rng_key, feedback\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m---> 10\u001B[0m   out_val \u001B[38;5;241m=\u001B[39m \u001B[43mclrs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeedback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictions_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m   predictions, _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(rng_key, test_feedback\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[1;32m     12\u001B[0m   out \u001B[38;5;241m=\u001B[39m clrs\u001B[38;5;241m.\u001B[39mevaluate(test_feedback\u001B[38;5;241m.\u001B[39moutputs, predictions)\n",
      "File \u001B[0;32m~/Stanford/Spring_2023/MS&E331/clrs/clrs/_src/evaluation.py:136\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(outputs, predictions)\u001B[0m\n\u001B[1;32m    134\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m truth\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m predictions\n\u001B[1;32m    135\u001B[0m   pred \u001B[38;5;241m=\u001B[39m predictions[truth\u001B[38;5;241m.\u001B[39mname]\n\u001B[0;32m--> 136\u001B[0m   evals[truth\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtruth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;66;03m# Return a single scalar score that is the mean of all output scores.\u001B[39;00m\n\u001B[1;32m    138\u001B[0m evals[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m evals\u001B[38;5;241m.\u001B[39mvalues()]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(evals)\n",
      "File \u001B[0;32m~/Stanford/Spring_2023/MS&E331/clrs/clrs/_src/evaluation.py:146\u001B[0m, in \u001B[0;36m_evaluate\u001B[0;34m(truth, pred, idx, lengths)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m pred\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m truth\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m pred\u001B[38;5;241m.\u001B[39mlocation \u001B[38;5;241m==\u001B[39m truth\u001B[38;5;241m.\u001B[39mlocation\n\u001B[0;32m--> 146\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m pred\u001B[38;5;241m.\u001B[39mtype_ \u001B[38;5;241m==\u001B[39m truth\u001B[38;5;241m.\u001B[39mtype_\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m truth\u001B[38;5;241m.\u001B[39mtype_ \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _EVAL_FN:\n\u001B[1;32m    149\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInvalid type\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Some intermediate results\n",
    "ALL: 0.5 dropout\n",
    "\n",
    "MPNN 100 train, 40 test, 100 epochs, self-loops -> loss = 0.9931782484054565 | val_acc = 0.8515625 | test_acc = 0.7484375238418579 | accuracy = 0.65, average nb non-matched: 13.45\n",
    "\n",
    "MPNN 200 train, 40 test, 100 epochs, self-loops -> loss = 0.8129420280456543 | val_acc = 0.8125 | test_acc = 0.77734375 | accuracy = 0.72, average nb non-matched: 11.125\n",
    "\n",
    "MPNN 100 train, 40 test, 100 epochs, double links -> loss = 0.8689386248588562 | val_acc = 0.7109375 | test_acc = 0.42695313692092896 | accuracy =? NOTE: only started \"learning\" in the last epochs => trying more, interestingly has less loss than self-loops but less accuracy too\n",
    "\n",
    "MPNN 100 train, 40 test, 200 epochs, double links -> step = 100 | loss = 0.6802611351013184 | val_acc = 0.806640625 | test_acc = 0.681640625 | accuracy = 0.89, average nb non-matched: 5.65\n",
    "\n",
    "MPNN 300 train, 40 test, 400 epochs, double links -> loss = 0.5485531091690063 | val_acc = 0.775390625 | test_acc = 0.6910156607627869 | accuracy = 0.928, average nb non-matched: 4.075 Note: best test_acc 0.727, similar test_acc to 100 train 200 epochs but better accuracy + still does not converge on training accuracy though\n",
    "\n",
    "Diff: length 100 testing instead of 64\n",
    "MPNN 100 train, 40 test LENGTH 100, 200 epochs, double links -> loss = 0.6958761215209961 | val_acc = 0.787109375 | test_acc = 0.503250002861023 | accuracy = 0.759, average nb non-matched: 7.9/100\n",
    "\n",
    "\n",
    "#### Now with actually bipartite graph (no owner-owner / good-good edges)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def matching_value(samples, predictions, partial = False):\n",
    "    features = samples.features\n",
    "    gt_matchings = samples.outputs[0].data\n",
    "    # inputs for the matrix A are at index 1 (see spec.py)\n",
    "    data = features.inputs[1].data\n",
    "    masks = features.inputs[3].data\n",
    "    pred_accuracy = 0\n",
    "\n",
    "    # Iterating over all the samples\n",
    "    for i in range(data.shape[0]):\n",
    "        max_weight = compute_greedy_matching_weight(i, data, masks, gt_matchings[i])\n",
    "\n",
    "        # TODO remove\n",
    "        predicted_matching = predictions[\"owners\"].data[i]\n",
    "        # buyers_mask = masks[i]\n",
    "        # n = int(np.sum(buyers_mask))\n",
    "        # permutation = np.random.permutation(np.arange(np.sum(buyers_mask == 0)))\n",
    "        # predicted_matching = np.concatenate((np.zeros(n), permutation))\n",
    "        if partial:\n",
    "            preds_weight = compute_partial_matching_weight(i, data, masks, predicted_matching)\n",
    "            print(f\"opt: {max_weight}, partial: {preds_weight}\")\n",
    "        else:\n",
    "            preds_weight = compute_greedy_matching_weight(i, data, masks, predicted_matching)\n",
    "            print(f\"opt: {max_weight}, partial: {preds_weight}\")\n",
    "\n",
    "        assert preds_weight <= max_weight\n",
    "        pred_accuracy += preds_weight / max_weight\n",
    "\n",
    "    return pred_accuracy / data.shape[0]\n",
    "\n",
    "def compute_greedy_matching_weight(i, data, masks, matching):\n",
    "    matching_weight = 0\n",
    "    A = data[i]\n",
    "    buyers_mask = masks[i]\n",
    "    n = int(np.sum(buyers_mask))\n",
    "    goods_mask = 1 - buyers_mask\n",
    "\n",
    "\n",
    "\n",
    "    # Only consider the matching values for consumers\n",
    "    matching = np.where(goods_mask == 1, matching, -1)\n",
    "\n",
    "    for buyer in range(n):\n",
    "        if buyer in matching:\n",
    "            # If several goods point to the same buyer, keep the one with maximum weight\n",
    "            matching_weight += np.max(A[buyer, matching == buyer])\n",
    "\n",
    "    return matching_weight\n",
    "\n",
    "def compute_partial_matching_weight(i, data, masks, matching):\n",
    "    # Matching is expected to be a (n+m)x(n+m) matrix where each row sums to 1 (weights assigned to other nodes)\n",
    "\n",
    "    matching_weight = 0\n",
    "    A = data[i]\n",
    "    buyers_mask = masks[i]\n",
    "    n = int(np.sum(buyers_mask))\n",
    "    goods_mask = 1 - buyers_mask\n",
    "    m = int(np.sum(goods_mask))\n",
    "\n",
    "    # We only care about the buyer -> good connections\n",
    "    A_submatrix = A[:n, n:n+m]\n",
    "    matching = matching[:n, n:n+m]\n",
    "\n",
    "    max_weight = np.max(np.sum(matching, axis = 0))\n",
    "    print(f\"max weight: {max_weight}\")\n",
    "    matching /= max_weight\n",
    "    return np.sum(matching * A_submatrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "test_feedback = next(test_sampler)\n",
    "predictions, _ = model.predict(rng_key, test_feedback.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weight: 1.5297893285751343\n",
      "opt: 22.509909997050908, partial: 14.029775619506836, greedy: 0\n",
      "max weight: 1.5107792615890503\n",
      "opt: 23.135114167854553, partial: 14.419025421142578, greedy: 0\n",
      "max weight: 1.5107792615890503\n",
      "opt: 23.135114167854553, partial: 14.419025421142578, greedy: 0\n",
      "max weight: 1.5683262348175049\n",
      "opt: 23.027825681330196, partial: 14.078963279724121, greedy: 0\n",
      "max weight: 1.3711823225021362\n",
      "opt: 22.79800465355557, partial: 15.573226928710938, greedy: 0\n",
      "max weight: 1.5052690505981445\n",
      "opt: 24.698609651980103, partial: 15.195359230041504, greedy: 0\n",
      "max weight: 1.3506972789764404\n",
      "opt: 23.933260816797336, partial: 16.73806381225586, greedy: 0\n",
      "max weight: 1.5683262348175049\n",
      "opt: 23.027825681330196, partial: 14.078963279724121, greedy: 0\n",
      "max weight: 1.700014352798462\n",
      "opt: 21.86007317728456, partial: 11.941967010498047, greedy: 0\n",
      "max weight: 1.352318286895752\n",
      "opt: 23.53177149762247, partial: 16.173660278320312, greedy: 0\n",
      "max weight: 1.3669893741607666\n",
      "opt: 24.734511097181954, partial: 17.136091232299805, greedy: 0\n",
      "max weight: 1.6356719732284546\n",
      "opt: 23.297689325161286, partial: 13.385599136352539, greedy: 0\n",
      "max weight: 1.5297893285751343\n",
      "opt: 22.509909997050908, partial: 14.029775619506836, greedy: 0\n",
      "max weight: 1.3731545209884644\n",
      "opt: 23.31125138563096, partial: 15.626424789428711, greedy: 0\n",
      "max weight: 1.7363685369491577\n",
      "opt: 22.803898596178044, partial: 12.452556610107422, greedy: 0\n",
      "max weight: 1.4297442436218262\n",
      "opt: 22.96577632013089, partial: 15.254743576049805, greedy: 0\n",
      "max weight: 1.5297893285751343\n",
      "opt: 22.509909997050908, partial: 14.029775619506836, greedy: 0\n",
      "max weight: 1.3733989000320435\n",
      "opt: 23.538594135628514, partial: 15.758846282958984, greedy: 0\n",
      "max weight: 1.4297442436218262\n",
      "opt: 22.96577632013089, partial: 15.254743576049805, greedy: 0\n",
      "max weight: 1.6356719732284546\n",
      "opt: 23.297689325161286, partial: 13.385599136352539, greedy: 0\n",
      "max weight: 1.3506972789764404\n",
      "opt: 23.933260816797336, partial: 16.73806381225586, greedy: 0\n",
      "max weight: 1.7363685369491577\n",
      "opt: 22.803898596178044, partial: 12.452556610107422, greedy: 0\n",
      "max weight: 1.3731545209884644\n",
      "opt: 23.31125138563096, partial: 15.626424789428711, greedy: 0\n",
      "max weight: 1.3731545209884644\n",
      "opt: 23.31125138563096, partial: 15.626424789428711, greedy: 0\n",
      "max weight: 1.390006422996521\n",
      "opt: 22.918464385602, partial: 15.601641654968262, greedy: 0\n",
      "max weight: 1.3745218515396118\n",
      "opt: 23.65658664712358, partial: 15.99682331085205, greedy: 0\n",
      "max weight: 1.5030527114868164\n",
      "opt: 24.06602186520245, partial: 14.79317855834961, greedy: 0\n",
      "max weight: 1.6436140537261963\n",
      "opt: 24.799464246118912, partial: 13.46316146850586, greedy: 0\n",
      "max weight: 1.3506972789764404\n",
      "opt: 23.933260816797336, partial: 16.73806381225586, greedy: 0\n",
      "max weight: 1.3711823225021362\n",
      "opt: 22.79800465355557, partial: 15.573226928710938, greedy: 0\n",
      "max weight: 1.4853932857513428\n",
      "opt: 23.55865351128988, partial: 14.871066093444824, greedy: 0\n",
      "max weight: 1.4980181455612183\n",
      "opt: 22.811493921988962, partial: 14.087488174438477, greedy: 0\n",
      "max weight: 1.4776943922042847\n",
      "opt: 23.207697190369466, partial: 14.6881103515625, greedy: 0\n",
      "max weight: 1.5168194770812988\n",
      "opt: 23.300593637327204, partial: 14.513895034790039, greedy: 0\n",
      "max weight: 1.5683262348175049\n",
      "opt: 23.027825681330196, partial: 14.078963279724121, greedy: 0\n",
      "max weight: 1.3170450925827026\n",
      "opt: 23.874207904745113, partial: 16.942909240722656, greedy: 0\n",
      "max weight: 1.403371810913086\n",
      "opt: 23.80507125076102, partial: 16.074487686157227, greedy: 0\n",
      "max weight: 1.3741203546524048\n",
      "opt: 24.582192536374674, partial: 16.045515060424805, greedy: 0\n",
      "max weight: 1.468819260597229\n",
      "opt: 23.543834648445962, partial: 15.143644332885742, greedy: 0\n",
      "max weight: 1.477693796157837\n",
      "opt: 23.207697190369466, partial: 14.688119888305664, greedy: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "Array(0.6384877, dtype=float32)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_value(test_feedback, predictions, partial = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminary results\n",
    "random permutation/matching: 0.18\n",
    "\n",
    "MPNN:\n",
    "learned predictions: 0.67\n",
    "\n",
    "GAT:\n",
    "learned predictions: 0.72\n",
    "\n",
    "Got better with double ended predictions\n",
    "\n",
    "Partial: 0.64 while greedy was doing about 0.92 on the same instance. Main reason seems to be that max weight is around 1.5 => can get at most 2/3 OPT\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counting the number of matching constraints violated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For two-way\n",
    "count = 0\n",
    "data = predictions[\"owners\"].data\n",
    "nb_graphs = data.shape[0]\n",
    "for datapoint in range(data.shape[0]):\n",
    "    for i in range(32):\n",
    "        owner = data[datapoint][i]\n",
    "        good = data[datapoint][int(owner)]\n",
    "        if good != i:\n",
    "            count += 1\n",
    "print(f\"average number of edges contradicting matching: {count / nb_graphs}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m nb_graphs \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m datapoint \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m----> 6\u001B[0m     owners \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdatapoint\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(owners)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage number of edges contradicting matching: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcount\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39mnb_graphs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# For self-loops\n",
    "count = 0\n",
    "data = predictions[\"owners\"].data\n",
    "nb_graphs = data.shape[0]\n",
    "for datapoint in range(data.shape[0]):\n",
    "    owners = set(np.array(data[datapoint][32:64]))\n",
    "    count += 32 - len(owners)\n",
    "print(f\"average number of edges contradicting matching: {count / nb_graphs}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , ..., 0.28533341, 0.26362947,\n        0.84964214],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.44046488,\n        0.        ],\n       ...,\n       [0.28533341, 0.        , 0.        , ..., 0.50471434, 0.        ,\n        0.        ],\n       [0.26362947, 0.        , 0.44046488, ..., 0.        , 0.23655434,\n        0.        ],\n       [0.84964214, 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whyyyyy are you not bipartite\n",
    "data = test_feedback.features.inputs[1].data[0]\n",
    "#data[:32, :32]\n",
    "data[32:64, 32:64]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "predictions, hints = model.predict(rng_key, test_feedback.features, return_hints = True, return_all_outputs = True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 40, 64, 64)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['owners'].data[::100].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "(16, 16)"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hints[10]['owners_h'][0].shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6, 4, 2])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6])\n",
    "arr[np.arange(len(arr)) % 2 == 0]\n",
    "arr[::2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.45111127,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.74242566,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 0.50471434, 0.        ,\n        0.        ],\n       [0.        , 0.45111127, 0.74242566, ..., 0.        , 0.23655434,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feedback.features.inputs[1].data[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
